{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  LSTM Base Model\n",
        "\n",
        "**Öğrenci:** Yazen Emino 22040301111\n",
        "\n",
        "Derin öğrenme dersi vize aşaması için geliştirilen **tek katmanlı LSTM** tabanlı temel modeli içermektedir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Model Mimarisi Diyagramı\n",
        "\n",
        "`Girdi (token id dizisi, uzunluk = 50)` → `Embedding (boyut = 50)` → `Tek Katmanlı LSTM (hidden = 64)` → `Son Zaman Adımının Gizli Durumu` → `Çıkış Katmanı (sınıf sayısı)` → `Softmax`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mimari Açıklaması\n",
        "\n",
        "Modelde her kelime önce 50 boyutlu embedding vektörüne dönüştürülmekte, ardından bu vektör dizisi tek katmanlı bir LSTM ağına verilmektedir. LSTM, kelimeleri sırayla işleyip geçmiş bilgiyi gizli durumda taşıyarak cümle içindeki bağlamı modellemeye çalışır. \n",
        "\n",
        "Son zaman adımındaki gizli durum, tüm sorunun özet temsili olarak kabul edilmekte ve sınıflandırma katmanına girdi olarak verilmektedir. Böylece model, sadece kelimelerin varlığını değil, aynı zamanda **kelime sırasını** da dikkate alarak tahmin üretmektedir.\n",
        "\n",
        "Tek katmanlı ve görece küçük boyutlu bir LSTM kullanılması, vize aşamasında istenen **shallow mimari** koşulunu sağlamaktadır.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Hiperparametreler ve Eğitim Ayarları\n",
        "\n",
        "- Embedding boyutu: **50**\n",
        "- LSTM gizli katman boyutu: **64**\n",
        "- LSTM katman sayısı: **1**\n",
        "- Öğrenme oranı (learning rate): **0.001**\n",
        "- Epoch sayısı: **8**\n",
        "- Batch size: **32**\n",
        "- Optimizasyon algoritması: **Adam**\n",
        "- Kayıp fonksiyonu: **CrossEntropyLoss**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"data/train.csv\")\n",
        "texts = df[\"text\"].astype(str).tolist()\n",
        "labels = df[\"label\"].tolist()\n",
        "\n",
        "print(\"Toplam örnek sayısı:\", len(texts))\n",
        "print(\"Örnek satırlar:\")\n",
        "display(df.head())\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Sınıflar:\", le.classes_)\n",
        "tokenized = [t.split() for t in texts]\n",
        "\n",
        "vocab = {}\n",
        "for sent in tokenized:\n",
        "    for w in sent:\n",
        "        if w not in vocab:\n",
        "            vocab[w] = len(vocab) + 1   \n",
        "\n",
        "max_len = 50\n",
        "\n",
        "def encode(tokens):\n",
        "    ids = [vocab.get(w, 0) for w in tokens][:max_len]\n",
        "    if len(ids) < max_len:\n",
        "        ids += [0] * (max_len - len(ids))\n",
        "    return ids\n",
        "\n",
        "X = np.array([encode(t) for t in tokenized], dtype=np.int64)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_ds = TextDataset(X_train, y_train)\n",
        "val_ds = TextDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. LSTM Mimarisi \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTMTextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=50, hidden_dim=64, num_layers=1, num_classes=num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=emb_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)                  \n",
        "        output, (h_n, c_n) = self.lstm(x)\n",
        "        h_last = h_n[-1]                       \n",
        "        logits = self.fc(h_last)\n",
        "        return logits\n",
        "\n",
        "lstm_model = LSTMTextClassifier(vocab_size=len(vocab)).to(device)\n",
        "lstm_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=8, lr=0.001):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "                val_running_loss += loss.item() * xb.size(0)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_targets.extend(yb.cpu().numpy())\n",
        "\n",
        "        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        acc = accuracy_score(all_targets, all_preds)\n",
        "        val_accuracies.append(acc)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {epoch_train_loss:.4f} - Val Loss: {epoch_val_loss:.4f} - Val Acc: {acc:.4f}\")\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.plot(val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Eğitim / Doğrulama Loss Eğrileri\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy grafiği\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(val_accuracies, label=\"Val Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Doğrulama Accuracy Eğrisi\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Modelin Eğitimi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lstm_model = train_model(lstm_model, train_loader, val_loader, epochs=8, lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion(cm, classes, title=\"Confusion Matrix\"):\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(cm, interpolation=\"nearest\")\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, ha=\"right\")\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = \"d\"\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel(\"Gerçek etiket\")\n",
        "    plt.xlabel(\"Tahmin edilen etiket\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate(model, loader, name=\"Validation\"):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_targets.extend(yb.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    f1_micro = f1_score(all_targets, all_preds, average=\"micro\")\n",
        "    f1_macro = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
        "    print(f\"{name} F1-Micro: {f1_micro:.4f}\")\n",
        "    print(f\"{name} F1-Macro: {f1_macro:.4f}\")\n",
        "    print(\"\\nSınıflandırma Raporu:\")\n",
        "    print(classification_report(all_targets, all_preds, target_names=le.classes_))\n",
        "\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "    plot_confusion(cm, le.classes_, title=f\"{name} Confusion Matrix\")\n",
        "\n",
        "    return acc, f1_micro, f1_macro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Değerlendirme Metrik Tablosu Sonuçları\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57206369",
      "metadata": {},
      "source": [
        "| **Metrik** | **Değer** |\n",
        "|-----------|-----------|\n",
        "| Accuracy  | 0.85 |\n",
        "| F1-Micro  | 0.84 |\n",
        "| F1-Macro  | 0.83 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e0b51d",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def show_final_table(acc, f1_micro, f1_macro):\n",
        "    tbl = \"## Nihai Değerlendirme Sonuçları (Tablo)\\n\\n\"\n",
        "    tbl += \"| **Metrik** | **Değer** |\\n\"\n",
        "    tbl += \"|-----------|-----------|\\n\"\n",
        "    tbl += f\"| Accuracy  | {acc:.4f} |\\n\"\n",
        "    tbl += f\"| F1-Micro  | {f1_micro:.4f} |\\n\"\n",
        "    tbl += f\"| F1-Macro  | {f1_macro:.4f} |\\n\"\n",
        "    return Markdown(tbl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sonuçların Ayrıntılı Yorumu – LSTM Modeli\n",
        "\n",
        "Doğrulama seti sonuçları, LSTM tabanlı modelin özellikle kelime sırasının önemli olduğu soru tiplerinde MLP'ye göre daha başarılı olduğunu göstermektedir. Elde edilen doğruluk ve F1 skorları, modelin bağlam bilgisinden yararlanabildiğini, ancak tek katmanlı ve sınırlı boyutlu bir yapı olduğundan 1D CNN modelinin biraz gerisinde kaldığını düşündürmektedir.\n",
        "\n",
        "LSTM modelinin en güçlü yönü, cümle içindeki **sıralı bağımlılıkları** modelleyebilmesidir. Buna karşın eğitim süresi MLP'ye göre daha uzundur ve uzun dizilerde gradyan sönümlenmesi gibi problemler ortaya çıkabilir.\n",
        "\n",
        "Final aşamasında, bu temel LSTM modeli; daha derin LSTM katmanları, attention mekanizmaları veya Transformer tabanlı mimariler ile genişletilerek performansın ne kadar artırılabileceğini incelemek için bir başlangıç noktası olarak kullanılacaktır.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
