{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Matematik Konu Sınıflandırma – 1D CNN Base Model\n",
        "\n",
        "**Öğrenci:** Muhammed Jalahej (22040301083)\n",
        "\n",
        "Derin Öğrenme dersi kapsamında vize değerlendirmesi için hazırlanmış sığ mimarili bir 1D CNN tabanlı metin sınıflandırma modelini içermektedir. Bu çalışmanın amacı, matematik sorularını doğru konu başlıklarına ayırabilen, yapısal olarak karmaşık olmayan ancak güçlü bir temel oluşturabilecek bir model geliştirmektir. Model, yüksek derinliğe sahip ağlar kullanılmadan, yalnızca konvolüsyonel filtrelerin sağladığı yerel örüntü yakalama gücüyle tatmin edici bir performans ortaya koyacak şekilde tasarlanmıştır."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Model Mimarisi Diyagramı\n",
        "\n",
        "Aşağıda kullandığım 1D CNN mimarisinin metin tabanlı diyagramı yer almaktadır:\n",
        "\n",
        "`Girdi (token id dizisi, uzunluk=50)`  →  `Embedding (boyut=64)`  →  `Conv1D (64 filtre, kernel=3)`  →  `ReLU`  →  `Flatten`  →  `Fully Connected (sınıf sayısı)`  →  `Softmax`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mimari Açıklaması\n",
        "\n",
        "- **Embedding katmanı:** Her kelimeyi 64 boyutlu yoğun vektör ile temsil eder. Bu sayede kelimeler arasında anlamsal benzerlikler kısmen yakalanır.\n",
        "- **1D Convolution (Conv1D):** 3 uzunluğunda kernel ile lokal n-gram paternlerini (ör. kısa kelime grupları) yakalamaya çalışır.\n",
        "- **ReLU aktivasyon:** Doğrusal olmayanlık ekleyerek modelin daha karmaşık karar sınırları öğrenmesini sağlar.\n",
        "- **Flatten + Tam Bağlantılı Katman:** Konvolüsyon çıktısını tek boyuta indirip **sınıf sayısı** kadar nörona bağlar.\n",
        "- **Softmax çıktısı:** Her sınıf için olasılık üretir; en yüksek olasılığa sahip etiket model tahmini olarak alınır.\n",
        "\n",
        "Bu yapı bilinçli olarak **tek konvolüsyon katmanlı** ve **shallow** tutulmuştur; amaç, finalde kullanacağımız daha gelişmiş modeller için bir benchmark oluşturmaktır."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Hiperparametreler \n",
        "\n",
        "Aşağıdaki hiperparametre kombinasyonları denenmiş ve en stabil, makul sonuç veren değerler seçilmiştir:\n",
        "\n",
        "- **Embedding boyutu:** 64\n",
        "- **Conv1D filtre sayısı:** 64\n",
        "- **Conv1D kernel boyutu:** 3\n",
        "- **Batch size:** 32\n",
        "- **Öğrenme oranı (learning rate):** 0.001\n",
        "- **Epoch sayısı:** 8\n",
        "- **Optimizasyon algoritması:** Adam\n",
        "- **Kayıp fonksiyonu:** CrossEntropyLoss\n",
        "\n",
        "Denemeler sonucunda 8 epoch civarında **validation loss** değerinin plato yapmaya başladığı, daha fazla epoch ile aşırı öğrenme (overfitting) ihtimalinin arttığı gözlemlenmiştir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "# Reprodüksiyon için sabit tohum (seed)\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Veri Yükleme\n",
        "df_train = pd.read_csv(\"data/train.csv\")\n",
        "df_test = pd.read_csv(\"data/test.csv\")\n",
        "\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Test shape :\", df_test.shape)\n",
        "print(df_train.head())\n",
        "\n",
        "# Sütun adları: text, label\n",
        "texts = df_train[\"text\"].astype(str).tolist()\n",
        "labels = df_train[\"label\"].tolist()\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Sınıf sayısı:\", num_classes)\n",
        "print(\"Sınıflar:\", le.classes_)\n",
        "\n",
        "# Basit tokenizasyon (whitespace)\n",
        "tokenized = [t.split() for t in texts]\n",
        "\n",
        "# Kelime haznesi\n",
        "vocab = {}\n",
        "for sent in tokenized:\n",
        "    for w in sent:\n",
        "        if w not in vocab:\n",
        "            vocab[w] = len(vocab) + 1  # 0: PAD\n",
        "\n",
        "max_len = 50\n",
        "\n",
        "def encode(sent_tokens):\n",
        "    ids = [vocab.get(w, 0) for w in sent_tokens][:max_len]\n",
        "    if len(ids) < max_len:\n",
        "        ids += [0] * (max_len - len(ids))\n",
        "    return ids\n",
        "\n",
        "X = np.array([encode(s) for s in tokenized], dtype=np.int64)\n",
        "y = np.array(labels, dtype=np.int64)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_ds = TextDataset(X_train, y_train)\n",
        "val_ds = TextDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 1D CNN Mimarisi, PyTorch Uygulaması"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class CNNTextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=64, num_filters=64, kernel_size=3, num_classes=num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, emb_dim, padding_idx=0)\n",
        "        self.conv = nn.Conv1d(in_channels=emb_dim,\n",
        "                              out_channels=num_filters,\n",
        "                              kernel_size=kernel_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(num_filters * (max_len - kernel_size + 1), num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)         \n",
        "        x = x.transpose(1, 2)          \n",
        "        x = self.conv(x)               \n",
        "        x = self.relu(x)\n",
        "        x = x.view(x.size(0), -1)      \n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "cnn_model = CNNTextClassifier(vocab_size=len(vocab)).to(device)\n",
        "cnn_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_confusion_matrix(cm, classes, title=\"Confusion Matrix\"):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cm, interpolation=\"nearest\")\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, ha=\"right\")\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = \"d\"\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel(\"Gerçek etiket\")\n",
        "    plt.xlabel(\"Tahmin edilen etiket\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate(model, data_loader, name=\"Val\"):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in data_loader:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "            logits = model(xb)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_targets.extend(yb.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    f1 = f1_score(all_targets, all_preds, average=\"weighted\")\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
        "    print(f\"{name} F1-score: {f1:.4f}\")\n",
        "    print(\"\\nSınıflandırma Raporu:\")\n",
        "    print(classification_report(all_targets, all_preds, target_names=le.classes_))\n",
        "\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "    plot_confusion_matrix(cm, le.classes_, title=f\"{name} Confusion Matrix\")\n",
        "\n",
        "    return acc, f1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Modelin Eğitimi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=8, lr=0.001):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb = xb.to(device)\n",
        "                yb = yb.to(device)\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "                val_running_loss += loss.item() * xb.size(0)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_targets.extend(yb.cpu().numpy())\n",
        "\n",
        "        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "\n",
        "        acc = accuracy_score(all_targets, all_preds)\n",
        "        val_accuracies.append(acc)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{epochs} | Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f} | Val Acc: {acc:.4f}\")\n",
        "\n",
        "    # Loss grafikleri\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.plot(val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Eğitim / Doğrulama Loss Eğrileri\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy grafiği\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(val_accuracies, label=\"Val Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Doğrulama Accuracy Eğrisi\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "cnn_model = train_model(cnn_model, train_loader, val_loader, epochs=8, lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Doğrulama Setinde Değerlendirme\n",
        "\n",
        "Burada doğrulama seti üzerinde accuracy, F1 skoru ve confusion matrix kullanarak modeli değerlendiriyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_acc, val_f1 = evaluate(cnn_model, val_loader, name='Validation')\n",
        "print('Validation Accuracy (kaydedilecek rapor):', val_acc)\n",
        "print('Validation F1 (kaydedilecek rapor):', val_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Nihai Değerlendirme Sonuçları\n",
        "Aşağıdaki tablo, modelin doğrulama setinden elde edilen **Final metrik sonuçlarını** göstermektedir:\n",
        "> Not: Bu değerler, evaluate() fonksiyonundan elde edilen çıktılardır.\n",
        "\n",
        "\n",
        "| **Metrik** | **Değer** |\n",
        "|-----------|-----------|\n",
        "| Accuracy | 0.88 |\n",
        "| F1-Micro | 0.88 |\n",
        "| F1-Macro | 0.86|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import numpy as np\n",
        "model = locals().get(list(globals().keys())[-1], None)\n",
        "model.eval()\n",
        "all_preds=[]\n",
        "all_targets=[]\n",
        "with torch.no_grad():\n",
        "    for xb,yb in val_loader:\n",
        "        xb=xb.to(device); yb=yb.to(device)\n",
        "        preds = model(xb).argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_targets.extend(yb.cpu().numpy())\n",
        "\n",
        "acc = accuracy_score(all_targets, all_preds)\n",
        "f1_micro = f1_score(all_targets, all_preds, average='micro')\n",
        "f1_macro = f1_score(all_targets, all_preds, average='macro')\n",
        "\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame({\n",
        "    'Metrik':['Accuracy','F1-Micro','F1-Macro'],\n",
        "    'Değer':[acc, f1_micro, f1_macro]\n",
        "})\n",
        "\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Markdown\n",
        "tbl = f\"\"\"\n",
        "## Nihai Değerlendirme Sonuçları (Tablo)\n",
        "| **Metrik** | **Değer** |\n",
        "|-----------|-----------|\n",
        "| Accuracy | {acc:.4f} |\n",
        "| F1-Micro | {f1_micro:.4f} |\n",
        "| F1-Macro | {f1_macro:.4f} |\n",
        "\"\"\"\n",
        "Markdown(tbl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Sonuçların Ayrıntılı Yorumu – 1D CNN Modeli\n",
        "\n",
        "1D CNN tabanlı model, doğrulama performansı açısından grubun en iyi sonuç veren temel modelidir. Özellikle yerel paternleri filtreleyen konvolüsyon yapısı, matematik sorularının içinde tekrar eden anahtar kelime ve ifade kalıplarını etkili bir şekilde yakalayabilmektedir.\n",
        "\n",
        "**Modelin güçlü yönleri:**\n",
        "- Konvolüsyon filtreleri sayesinde kelime gruplarındaki lokal ilişkileri iyi öğrenir.\n",
        "- Eğitim süresi LSTM’e göre daha kısa, MLP’ye göre ise daha kararlı sonuç üretmektedir.\n",
        "- Verideki gürültüye karşı daha dayanıklıdır.\n",
        "\n",
        "**Modelin zayıf yönleri:**\n",
        "- Kelimelerin uzun bağımlılıklarını (long-range dependencies) LSTM kadar iyi yakalayamaz.\n",
        "- Embedding + Conv1D yapısı, daha karmaşık semantik ilişkileri sınırlı düzeyde modeller.\n",
        "\n",
        "**Sonuçların yorumu:**\n",
        "Model doğrulama setinde yaklaşık **0.8871 Accuracy**, **0.8834 F1-Micro**, ve **0.8649 F1-Macro** skorlarına ulaşmıştır. Bu metrikler, CNN yapısının veri setinin yapısına oldukça uygun olduğunu göstermektedir. Özellikle Micro F1 skorunun yüksek olması, modelin genel sınıflar üzerinde tutarlı performans verdiğini işaret eder.\n",
        "\n",
        "Macro F1 skorunun Micro F1’e göre biraz daha düşük olması, bazı sınıflarda veri dengesizliği veya daha zor öğrenilen kategoriler bulunabileceğini göstermektedir. Buna rağmen CNN modeli, diğer iki temel modele kıyasla en kararlı ve yüksek doğruluğa sahip sonuçları sunmuştur.\n",
        "\n",
        "**Genel değerlendirme:**\n",
        "Bu model final aşamasında uygulanacak daha gelişmiş mimariler için güçlü bir başlangıç noktasıdır. Özellikle daha derin CNN yapıları, attention tabanlı mekanizmalar veya Transformer modelleri ile birleştirildiğinde daha yüksek performans elde edilebileceği açıktır.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Eğitim ve Doğrulama Kayıp Eğrileri (Loss Curves)\n",
        "Aşağıdaki grafikler, modelin epoch'lar boyunca nasıl öğrendiğini ve doğrulama kaybının nasıl değiştiğini gösterir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.title(\"Eğitim ve Doğrulama Loss Grafiği\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Sınıf Bazında Doğruluk (Class-Wise Accuracy)\n",
        "Her bir sınıf için modelin doğruluğunu hesaplayan analiz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "preds = []\n",
        "trues = []\n",
        "\n",
        "cnn_model.eval()\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_loader:\n",
        "        xb = xb.to(device)\n",
        "        out = cnn_model(xb)\n",
        "        p = out.argmax(1).cpu().numpy()\n",
        "        preds.extend(p)\n",
        "        trues.extend(yb.numpy())\n",
        "\n",
        "preds = np.array(preds)\n",
        "trues = np.array(trues)\n",
        "\n",
        "class_acc = {}\n",
        "for cls_idx, cls_name in enumerate(le.classes_):\n",
        "    mask = trues == cls_idx\n",
        "    if mask.sum() > 0:\n",
        "        class_acc[cls_name] = (preds[mask] == trues[mask]).mean()\n",
        "    else:\n",
        "        class_acc[cls_name] = 0.0\n",
        "\n",
        "class_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Model Mimarisi Şeması\n",
        "Aşağıdaki diyagram, 1D CNN modelinin veri akışını özetlemektedir:\n",
        "\n",
        "```\n",
        "Girdi (Token ID Dizisi, 50 uzunluk)\n",
        "        │\n",
        "        ▼\n",
        "Embedding (64 boyut)\n",
        "        │ [batch, 50, 64]\n",
        "        ▼\n",
        "Conv1D (64 filtre, kernel=3)\n",
        "        │ [batch, 64, 48]\n",
        "        ▼\n",
        "Flatten\n",
        "        │ [batch, 64*48]\n",
        "        ▼\n",
        "Fully Connected Layer\n",
        "        │ [batch, sınıf sayısı]\n",
        "        ▼\n",
        "Softmax (Çıkış)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Derinlemesine Model Analizi ve Tartışma\n",
        "Bu bölümde modelin neden başarılı olduğu, mimarinin avantajları, veri setinin yapısı ile olan uyumu ve gelecekte yapılabilecek geliştirmeler daha ayrıntılı şekilde tartışılmaktadır.\n",
        "\n",
        "### CNN'in Başarısının Temel Sebepleri\n",
        "- **Yerel patern öğrenimi:** Matematik problemlerinde belirli kelime grupları (ör. 'integral', 'limit', 'açısal hız') son derece belirleyicidir. CNN filtreleri bu tip lokal kelime kümelerini çok etkili yakalar.\n",
        "- **Sabit filtre boyutları:** Kernel=3 gibi küçük filtreler, kısa kelime dizilimlerini tanımada çok başarılıdır.\n",
        "- **Dil bağımsızlığı:** RNN gibi sıralı bağımlılığa aşırı bağlı değildir, bu da modeli daha hızlı ve daha kararlı yapar.\n",
        "\n",
        "### Neden LSTM’den Daha İyi\n",
        "- LSTM uzun bağımlılıkları yakalayabilir ama **daha fazla parametre** içerir.\n",
        "- LSTM eğitim süresi daha uzundur.\n",
        "- Küçük veri setlerinde CNN **daha stabil** çalışır.\n",
        "\n",
        "### Neden MLP’den Çok Daha İyi\n",
        "- MLP kelime dizisini 'sırasız' bir vektör gibi işler → bilgi kaybı.\n",
        "- CNN ise konvolüsyon filtreleriyle **sıralı lokal bilgiyi** korur.\n",
        "- Bu nedenle CNN, metin verisinde MLP'ye göre belirgin şekilde üstündür.\n",
        "\n",
        "### Veri Seti ile Uyumu\n",
        "Matematik problemlerinde anlam çoğunlukla **lokal kelime paternlerinden** gelir. CNN tam olarak bu tür paternleri yakalamak üzere tasarlanmıştır. Bu yüzden CNN modeli veri setiyle doğal bir uyum sağlar.\n",
        "\n",
        "### Gelecek Geliştirmeler İçin Öneriler\n",
        "- Daha derin CNN katmanları eklenebilir.\n",
        "- Dil modeli tabanlı embedding'ler (Word2Vec, FastText, BERT embedding) kullanılabilir.\n",
        "- CNN + Attention hibrit modelleri ile daha iyi sonuçlar elde edilebilir.\n",
        "- Transformer mimarisine geçiş, final projede çok büyük performans artışı sağlayacaktır.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
