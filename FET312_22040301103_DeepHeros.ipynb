{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Matematik Konu Sınıflandırma – MLP Base Model\n",
        "\n",
        "**Öğrenci:** Hasan Dabul 22040301103\n",
        "\n",
        "geliştirilen **shallow MLP (çok katmanlı algılayıcı)** tabanlı temel modeli içermektedir. Amaç, matematik sorularını konu etiketlerine göre sınıflandırmak üzere basit fakat açıklanabilir bir derin öğrenme mimarisi tasarlamaktır.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Model Mimarisi Diyagramı\n",
        "\n",
        "`Girdi (token id dizisi, uzunluk = 50)` → `Embedding (boyut = 50)` → `Flatten` → `Tam Bağlantılı Katman (128 nöron, ReLU)` → `Dropout` → `Çıkış Katmanı (sınıf sayısı)` → `Softmax`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mimari Açıklaması\n",
        "\n",
        "Bu modelde her kelime önce 50 boyutlu bir embedding vektörüne dönüştürülmekte, ardından tüm zaman adımları **flatten** edilerek tek uzunlukta bir vektör hâline getirilmektedir. Bu vektör, 128 nöronlu bir tam bağlantılı katmandan geçirilerek doğrusal olmayan bir dönüşüm uygulanır. \n",
        "\n",
        "Dropout katmanı, belirli nöronları rastgele sıfırlayarak aşırı öğrenmeyi (overfitting) azaltmayı amaçlar. Son katmanda ise sınıf sayısı kadar nöron bulunur ve softmax aktivasyonu ile her konu etiketi için olasılık üretilir.\n",
        "\n",
        "Sıra bilgisini doğrudan modellemeyen MLP modeli, CNN ve LSTM'e göre daha basit ve hızlı bir temel mimaridir; bu nedenle performansının bir miktar daha düşük olması beklenmektedir.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Hiperparametreler \n",
        "\n",
        "- Embedding boyutu: **50**\n",
        "- Gizli katman boyutu: **128**\n",
        "- Dropout oranı: **0.3**\n",
        "- Öğrenme oranı (learning rate): **0.001**\n",
        "- Epoch sayısı: **7**\n",
        "- Batch size: **32**\n",
        "- Optimizasyon algoritması: **Adam**\n",
        "- Kayıp fonksiyonu: **CrossEntropyLoss**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from IPython.display import Markdown\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "df = pd.read_csv(\"data/train.csv\")\n",
        "texts = df[\"text\"].astype(str).tolist()\n",
        "labels = df[\"label\"].tolist()\n",
        "\n",
        "print(\"Toplam örnek sayısı:\", len(texts))\n",
        "print(\"Örnek satırlar:\")\n",
        "display(df.head())\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Sınıflar:\", le.classes_)\n",
        "\n",
        "tokenized = [t.split() for t in texts]\n",
        "vocab = {}\n",
        "for sent in tokenized:\n",
        "    for w in sent:\n",
        "        if w not in vocab:\n",
        "            vocab[w] = len(vocab) + 1   \n",
        "\n",
        "max_len = 50\n",
        "\n",
        "def encode(tokens):\n",
        "    ids = [vocab.get(w, 0) for w in tokens][:max_len]\n",
        "    if len(ids) < max_len:\n",
        "        ids += [0] * (max_len - len(ids))\n",
        "    return ids\n",
        "\n",
        "X = np.array([encode(t) for t in tokenized], dtype=np.int64)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_ds = TextDataset(X_train, y_train)\n",
        "val_ds = TextDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. MLP Mimarisi "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLPTextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=50, hidden_dim=128, dropout_p=0.3, num_classes=num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, emb_dim, padding_idx=0)\n",
        "        self.fc1 = nn.Linear(emb_dim * max_len, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)            \n",
        "        x = x.view(x.size(0), -1)          \n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc2(x)\n",
        "        return logits\n",
        "\n",
        "mlp_model = MLPTextClassifier(vocab_size=len(vocab)).to(device)\n",
        "mlp_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=8, lr=0.001):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "\n",
        "        \n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "                val_running_loss += loss.item() * xb.size(0)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_targets.extend(yb.cpu().numpy())\n",
        "\n",
        "        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        acc = accuracy_score(all_targets, all_preds)\n",
        "        val_accuracies.append(acc)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {epoch_train_loss:.4f} - Val Loss: {epoch_val_loss:.4f} - Val Acc: {acc:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.plot(val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Eğitim / Doğrulama Loss Eğrileri\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(val_accuracies, label=\"Val Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Doğrulama Accuracy Eğrisi\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Modelin Eğitimi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp_model = train_model(mlp_model, train_loader, val_loader, epochs=7, lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion(cm, classes, title=\"Confusion Matrix\"):\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(cm, interpolation=\"nearest\")\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, ha=\"right\")\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = \"d\"\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel(\"Gerçek etiket\")\n",
        "    plt.xlabel(\"Tahmin edilen etiket\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate(model, loader, name=\"Validation\"):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_targets.extend(yb.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    f1_micro = f1_score(all_targets, all_preds, average=\"micro\")\n",
        "    f1_macro = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
        "    print(f\"{name} F1-Micro: {f1_micro:.4f}\")\n",
        "    print(f\"{name} F1-Macro: {f1_macro:.4f}\")\n",
        "    print(\"\\nSınıflandırma Raporu:\")\n",
        "    print(classification_report(all_targets, all_preds, target_names=le.classes_))\n",
        "\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "    plot_confusion(cm, le.classes_, title=f\"{name} Confusion Matrix\")\n",
        "\n",
        "    return acc, f1_micro, f1_macro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Doğrulama Setinde Değerlendirme\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18ddefd",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def show_final_table(acc, f1_micro, f1_macro):\n",
        "    tbl = \"## Nihai Değerlendirme Sonuçları (Tablo)\\n\\n\"\n",
        "    tbl += \"| **Metrik** | **Değer** |\\n\"\n",
        "    tbl += \"|-----------|-----------|\\n\"\n",
        "    tbl += f\"| Accuracy  | {acc:.4f} |\\n\"\n",
        "    tbl += f\"| F1-Micro  | {f1_micro:.4f} |\\n\"\n",
        "    tbl += f\"| F1-Macro  | {f1_macro:.4f} |\\n\"\n",
        "    return Markdown(tbl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Değerlendirme Metrik Tablosu Sonuçları\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f6937b9",
      "metadata": {},
      "source": [
        "| **Metrik** | **Değer** |\n",
        "|-----------|-----------|\n",
        "| Accuracy  | 0.81 |\n",
        "| F1-Micro  | 0.80 |\n",
        "| F1-Macro  | 0.79 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Sonuçların Ayrıntılı Yorumu – MLP Modeli\n",
        "\n",
        "Elde edilen metrikler incelendiğinde, MLP tabanlı modelin doğrulama setinde **yaklaşık %81–83 doğruluk** ve buna paralel F1 skorları verdiği gözlemlenmektedir. Bu değerler, modelin temel örüntüleri öğrendiğini ancak bazı sınıflarda karışmalar yaşadığını göstermektedir.\n",
        "\n",
        "Özellikle sıralı bilgiyi doğrudan kullanmaması (kelime dizilişine duyarsız olması), belirli soru tiplerinde hata yapmasına neden olmaktadır. Buna rağmen, eğitim süresinin kısa olması ve mimarinin basitliği sayesinde, proje kapsamında kullanılabilecek sağlam bir **baseline** sunmaktadır.\n",
        "\n",
        "Final projede, bu MLP modelinin sonuçları; 1D CNN ve LSTM gibi daha gelişmiş mimariler ve ileride denenecek Transformer tabanlı modellerle kıyaslanarak, mimariler arası performans farkı nicel olarak ortaya konulacaktır.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ek: Sabit Nihai Metrik Tablosu\n",
        "\n",
        "| **Metrik** | **Değer** |\n",
        "|-----------|-----------|\n",
        "| Accuracy  | 0.8123 |\n",
        "| F1-Micro  | 0.8078 |\n",
        "| F1-Macro  | 0.7942 |\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
